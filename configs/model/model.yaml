_target_: "src.models.pigvae_auto_module.PLGraphAE"

graph_ae:
  _target_: "src.models.components.modules.GraphAE"
  hparams:
    input_size: 256
    num_heads: 4
    num_layers: 4
    vae: true
    encoder:
      n: ${model.graph_ae.hparams.input_size}
      num_node_features: 16
      num_edge_features: 0
      graph_encoder_num_heads: ${model.graph_ae.hparams.num_heads}
      graph_encoder_ppf_hidden_dim: ${multiply:${model.graph_ae.hparams.input_size},4}
      graph_encoder_num_layers: ${model.graph_ae.hparams.num_layers}
      emb_dim: ${model.graph_ae.hparams.input_size}
      grid_size: 6

    decoder:
      graph_decoder_hidden_dim: ${model.graph_ae.hparams.input_size}
      graph_decoder_pos_emb_dim: ${model.graph_ae.hparams.input_size}
      graph_decoder_num_heads: ${model.graph_ae.hparams.num_heads}
      graph_decoder_ppf_hidden_dim: ${multiply:${model.graph_ae.hparams.input_size},4}
      graph_decoder_num_layers: ${model.graph_ae.hparams.num_layers}
      num_node_features: 16
      num_edge_features: 0

    bottle_neck_encoder:
      graph_encoder_hidden_dim: ${model.graph_ae.hparams.input_size}
      emb_dim: 32 # zwiekszyl latent 
      vae: true

    bottle_neck_decoder:
      emb_dim: 32
      graph_decoder_hidden_dim: ${model.graph_ae.hparams.input_size}

    property_predictor:
      emb_dim: 32
      property_predictor_hidden_dim: ${model.graph_ae.hparams.input_size}
      num_properties: 1

    permuter:
      graph_decoder_hidden_dim: ${model.graph_ae.hparams.input_size}
      num_permutations: 8
      grid_size: 6
      tau: 1.0

critic:
  _target_: "src.models.components.model.Critic"
  hparams:
    kld_loss_scale: 0.001
    perm_loss_scale: 0.01
    property_loss_scale: 0.01
    vae: true

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.0006921113055205339
  weight_decay: 0.0

scheduler:
  batch_size: ${data.batch_size}

compile: false


