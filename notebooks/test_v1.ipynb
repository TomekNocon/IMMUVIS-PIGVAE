{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52d9f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rootutils\n",
    "\n",
    "rootutils.setup_root(os.getcwd(), indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from src.data.components.graphs_datamodules import (\n",
    "    IMCBaseDictTransform,\n",
    "    PickleDataset,\n",
    "    PatchAugmentations,\n",
    ")\n",
    "from src.data.imc_datamodule import add_channel\n",
    "import src.data.components.graphs_datamodules as gd\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import ConcatDataset, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4286e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25558e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.plot import restore_tensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_transforms = IMCBaseDictTransform()\n",
    "\n",
    "aug_transforms_train = gd.PatchAugmentations(\n",
    "    prob=1.0,\n",
    "    size=13,\n",
    "    patch_size=1,\n",
    ")\n",
    "\n",
    "aug_transforms_val = gd.PatchAugmentations(\n",
    "    prob=1.0,\n",
    "    size=13,\n",
    "    patch_size=1,\n",
    "    is_validation=True,\n",
    ")\n",
    "\n",
    "dual_transforms_train = gd.DualOutputTransform(base_transforms, aug_transforms_train)\n",
    "\n",
    "dual_transforms_val = gd.DualOutputTransform(base_transforms, aug_transforms_val)\n",
    "\n",
    "train_path = Path(\"../data\") / 'IMC-sample' / 'train.h5'\n",
    "test_path = Path(\"../data\") / 'IMC-sample' / 'test.h5'\n",
    "trainset = PickleDataset(train_path, transform=dual_transforms_train)\n",
    "testset = PickleDataset(train_path, transform=dual_transforms_val)\n",
    "train_ratio, val_ratio, test_ratio, leftover_ratio = [3600, 1044, 0, 0]\n",
    "size_testset = len(testset)\n",
    "size_trainset = len(trainset)\n",
    "data_train, _ = random_split(\n",
    "    dataset=trainset,\n",
    "    lengths=[train_ratio, size_trainset - train_ratio],\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")\n",
    "# dataset = ConcatDataset(datasets=[trainset, testset])\n",
    "data_val, data_test, _ = random_split(\n",
    "    dataset=testset,\n",
    "    lengths=[val_ratio, test_ratio, size_testset - val_ratio - test_ratio],\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")\n",
    "\n",
    "train_dataset = gd.GridGraphDataset(grid_size=13, dataset=data_train, channels=list(range(10)))\n",
    "\n",
    "train_loader = gd.DenseGraphDataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=8,\n",
    "    num_workers=7,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=7 > 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099e6d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.data.components.graphs_datamodules.DenseGraphBatch object at 0x1108be120>\n"
     ]
    }
   ],
   "source": [
    "for el in train_loader:\n",
    "    print(el)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "311d6885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 169, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el.node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4717a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules for PLGraphAE\n",
    "import os\n",
    "import rootutils\n",
    "\n",
    "rootutils.setup_root(os.getcwd(), indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from src.models.pigvae_auto_module import PLGraphAE\n",
    "from src.models.components.modules import GraphAE\n",
    "from src.models.components.schedulers import TemperatureScheduler, EntropyWeightScheduler\n",
    "from src.models.components.model import Critic\n",
    "from src.data.components.graphs_datamodules import DenseGraphBatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2685f657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting configurations to DictConfig...\n",
      "Creating GraphAE from resolved config...\n",
      "GraphAE created successfully!\n",
      "Creating schedulers...\n",
      "Creating critic...\n",
      "Creating optimizer (dummy for loading)...\n",
      "Creating scheduler (dummy for loading)...\n",
      "All components created successfully!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Path to your YAML config file\n",
    "config_path = \"../configs/model/model.yaml\"\n",
    "\n",
    "# Load the YAML file\n",
    "with open(config_path, \"r\") as f:\n",
    "    model_config_raw = yaml.safe_load(f)\n",
    "\n",
    "print(\"Converting configurations to DictConfig...\")\n",
    "\n",
    "# Register custom OmegaConf resolvers for multiply and divide\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Register multiply resolver if not already registered\n",
    "if not OmegaConf.has_resolver(\"multiply\"):\n",
    "    OmegaConf.register_new_resolver(\"multiply\", lambda x, y: x * y)\n",
    "\n",
    "# Register divide resolver if not already registered\n",
    "if not OmegaConf.has_resolver(\"divide\"):\n",
    "    OmegaConf.register_new_resolver(\"divide\", lambda x, y: x // y)\n",
    "\n",
    "# Wrap the config under 'model' and 'data' keys so interpolations work\n",
    "# Also provide the missing data.hparams.num_aug_per_sample value\n",
    "full_config = OmegaConf.create({\n",
    "    \"model\": model_config_raw,\n",
    "    \"data\": {\n",
    "        \"hparams\": {\n",
    "            \"num_aug_per_sample\": 8,\n",
    "            \"batch_size\": 8\n",
    "        }\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"max_epochs\": 500,  # Set these to match your training config\n",
    "        \"min_epochs\": 1\n",
    "    }\n",
    "})\n",
    "\n",
    "# Now resolve all interpolations\n",
    "OmegaConf.resolve(full_config)\n",
    "\n",
    "print(\"Creating GraphAE from resolved config...\")\n",
    "graph_ae = GraphAE(hparams=full_config.model.graph_ae.hparams)\n",
    "print(\"GraphAE created successfully!\")\n",
    "\n",
    "print(\"Creating schedulers...\")\n",
    "temperature_scheduler = TemperatureScheduler(hparams=full_config.model.temperature_scheduler.hparams)\n",
    "entropy_weight_scheduler = EntropyWeightScheduler(hparams=full_config.model.entropy_weight_scheduler.hparams)\n",
    "\n",
    "print(\"Creating critic...\")\n",
    "critic = Critic(hparams=full_config.model.critic.hparams)\n",
    "\n",
    "print(\"Creating optimizer (dummy for loading)...\")\n",
    "# Create a dummy optimizer for loading (it will be overridden by the checkpoint)\n",
    "optimizer = torch.optim.Adam(graph_ae.parameters(), lr=0.0001)\n",
    "\n",
    "print(\"Creating scheduler (dummy for loading)...\")\n",
    "# Create a dummy scheduler for loading\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "\n",
    "print(\"All components created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67aecfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PLGraphAE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasznocon/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'critic' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['critic'])`.\n",
      "/Users/tomasznocon/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'temperature_scheduler' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['temperature_scheduler'])`.\n",
      "/Users/tomasznocon/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'entropy_weight_scheduler' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['entropy_weight_scheduler'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLGraphAE model created successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasznocon/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'graph_ae' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['graph_ae'])`.\n"
     ]
    }
   ],
   "source": [
    "# Create the PLGraphAE model\n",
    "print(\"Creating PLGraphAE model...\")\n",
    "model = PLGraphAE(\n",
    "    graph_ae=graph_ae,\n",
    "    critic=critic,\n",
    "    temperature_scheduler=temperature_scheduler,\n",
    "    entropy_weight_scheduler=entropy_weight_scheduler,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "print(\"PLGraphAE model created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acd71067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: ../logs/train/runs/2025-10-14_23-57-01/checkpoints/last.ckpt\n",
      "This may take a moment...\n",
      "Checkpoint loaded successfully!\n",
      "Model weights loaded successfully!\n",
      "Model is ready for inference!\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint_path = \"../logs/train/runs/2025-10-14_23-57-01/checkpoints/last.ckpt\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "print(\"This may take a moment...\")\n",
    "\n",
    "# Load the checkpoint with weights_only=False since this is a Lightning checkpoint\n",
    "# that contains more than just weights (it's safe since this is our own trained model)\n",
    "checkpoint = torch.load(checkpoint_path, map_location='mps', weights_only=False)\n",
    "print(\"Checkpoint loaded successfully!\")\n",
    "\n",
    "# Load the state dict into the model\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Model weights loaded successfully!\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "print(\"Model is ready for inference!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddf4c20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to device: mps\n",
      "\n",
      "Model loaded successfully!\n",
      "- Checkpoint epoch: 499\n",
      "- Global step: 510\n",
      "- Model device: mps:0\n",
      "- Model parameters: 18,023,049\n",
      "- Trainable parameters: 18,022,921\n"
     ]
    }
   ],
   "source": [
    "# Optional: Move model to GPU if available\n",
    "device = 'mps'\n",
    "model = model.to(device)\n",
    "print(f\"Model moved to device: {device}\")\n",
    "\n",
    "# Display model summary\n",
    "print(\"\\nModel loaded successfully!\")\n",
    "print(f\"- Checkpoint epoch: {checkpoint.get('epoch', 'Unknown')}\")\n",
    "print(f\"- Global step: {checkpoint.get('global_step', 'Unknown')}\")\n",
    "print(f\"- Model device: {next(model.parameters()).device}\")\n",
    "print(f\"- Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"- Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fc27527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.plot import restore_tensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_transforms = IMCBaseDictTransform()\n",
    "\n",
    "aug_transforms_train = gd.PatchAugmentations(\n",
    "    prob=1.0,\n",
    "    size=13,\n",
    "    patch_size=1,\n",
    ")\n",
    "\n",
    "aug_transforms_val = gd.PatchAugmentations(\n",
    "    prob=1.0,\n",
    "    size=13,\n",
    "    patch_size=1,\n",
    "    is_validation=True,\n",
    ")\n",
    "\n",
    "dual_transforms_train = gd.DualOutputTransform(base_transforms, aug_transforms_train)\n",
    "\n",
    "dual_transforms_val = gd.DualOutputTransform(base_transforms, aug_transforms_val)\n",
    "\n",
    "train_path = Path(\"../data\") / 'IMC-sample' / 'train.h5'\n",
    "test_path = Path(\"../data\") / 'IMC-sample' / 'test.h5'\n",
    "trainset = PickleDataset(train_path, transform=dual_transforms_train)\n",
    "testset = PickleDataset(train_path, transform=dual_transforms_val)\n",
    "train_ratio, val_ratio, test_ratio, leftover_ratio = [3600, 1044, 0, 0]\n",
    "size_testset = len(testset)\n",
    "size_trainset = len(trainset)\n",
    "data_train, _ = random_split(\n",
    "    dataset=trainset,\n",
    "    lengths=[train_ratio, size_trainset - train_ratio],\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")\n",
    "# dataset = ConcatDataset(datasets=[trainset, testset])\n",
    "data_val, data_test, _ = random_split(\n",
    "    dataset=testset,\n",
    "    lengths=[val_ratio, test_ratio, size_testset - val_ratio - test_ratio],\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")\n",
    "\n",
    "train_dataset = gd.GridGraphDataset(grid_size=13, dataset=data_train, channels=list(range(10)))\n",
    "\n",
    "train_loader = gd.DenseGraphDataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=8,\n",
    "    num_workers=7,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=7 > 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a62d1fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8695df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "el = el.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa1bdf8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (169x10 and 1x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m model.eval()\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     graph_emb, graph_pred, soft_probs, perm, mu, logvar = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/src/models/pigvae_auto_module.py:85\u001b[39m, in \u001b[36mPLGraphAE.forward\u001b[39m\u001b[34m(self, graph, training, tau)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph: DenseGraphBatch, training: \u001b[38;5;28mbool\u001b[39m, tau: \u001b[38;5;28mfloat\u001b[39m) -> Tuple:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     graph_emb, graph_pred, soft_probs, perm, mu, logvar = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph_ae\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m graph_emb, graph_pred, soft_probs, perm, mu, logvar\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/src/models/components/modules.py:62\u001b[39m, in \u001b[36mGraphAE.forward\u001b[39m\u001b[34m(self, graph, training, tau)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m, graph: DenseGraphBatch, training: \u001b[38;5;28mbool\u001b[39m, tau: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m1.0\u001b[39m\n\u001b[32m     61\u001b[39m ) -> Tuple:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     graph_emb, node_features, mu, logvar = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     perm, context, soft_probs, _ = \u001b[38;5;28mself\u001b[39m.permuter(\n\u001b[32m     64\u001b[39m         node_features, mask=graph.mask, hard=\u001b[38;5;129;01mnot\u001b[39;00m training, tau=tau\n\u001b[32m     65\u001b[39m     )\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/src/models/components/modules.py:33\u001b[39m, in \u001b[36mGraphAE.encode\u001b[39m\u001b[34m(self, graph)\u001b[39m\n\u001b[32m     31\u001b[39m edge_features = graph.edge_features\n\u001b[32m     32\u001b[39m mask = graph.mask\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m graph_emb, node_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m graph_emb, mu, logvar = \u001b[38;5;28mself\u001b[39m.bottle_neck_encoder(graph_emb)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m graph_emb, node_features, mu, logvar\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/src/models/components/modules.py:136\u001b[39m, in \u001b[36mGraphEncoder.forward\u001b[39m\u001b[34m(self, node_features, edge_features, mask)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    130\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    131\u001b[39m     node_features: torch.Tensor,\n\u001b[32m    132\u001b[39m     edge_features: torch.Tensor,\n\u001b[32m    133\u001b[39m     mask: torch.Tensor,\n\u001b[32m    134\u001b[39m ) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.project:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m         node_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprojection_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     x, _ = \u001b[38;5;28mself\u001b[39m.init_message_matrix(node_features, edge_features, mask)\n\u001b[32m    138\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.graph_transformer(x, mask=\u001b[38;5;28;01mNone\u001b[39;00m, is_encoder=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MIM/Repositories/Master thesis/immuvis/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: linear(): input and weight.T shapes cannot be multiplied (169x10 and 1x512)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    graph_emb, graph_pred, soft_probs, perm, mu, logvar = model(el, training=False, tau=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b27919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f4cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f2cc37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
